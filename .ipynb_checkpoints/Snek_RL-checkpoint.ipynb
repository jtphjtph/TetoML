{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068efb1-a7ac-4e35-9d7b-b25b3b8fdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "SNAKE_LEN_GOAL = 30\n",
    "\n",
    "def collision_with_apple(apple_position, score):\n",
    "\tapple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "\tscore += 1\n",
    "\treturn apple_position, score\n",
    "\n",
    "def collision_with_boundaries(snake_head):\n",
    "\tif snake_head[0]>=500 or snake_head[0]<0 or snake_head[1]>=500 or snake_head[1]<0 :\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "def collision_with_self(snake_position):\n",
    "\tsnake_head = snake_position[0]\n",
    "\tif snake_head in snake_position[1:]:\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "\n",
    "class SnekEnv(gym.Env):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(SnekEnv, self).__init__()\n",
    "\t\t# Define action and observation space\n",
    "\t\t# They must be gym.spaces objects\n",
    "\t\t# Example when using discrete actions:\n",
    "\t\tself.action_space = spaces.Discrete(4)\n",
    "\t\t# Example for using image as input (channel-first; channel-last also works):\n",
    "\t\tself.observation_space = spaces.Box(low=-500, high=500,\n",
    "\t\t\t\t\t\t\t\t\t\t\tshape=(5+SNAKE_LEN_GOAL,), dtype=np.float32)\n",
    "\n",
    "\tdef step(self, action):\n",
    "\t\tself.prev_actions.append(action)\n",
    "\t\tcv2.imshow('a',self.img)\n",
    "\t\t#cv2.waitKey(1)\n",
    "        \n",
    "\t\tself.img = np.zeros((500,500,3),dtype='uint8')\n",
    "\t\t# Display Apple\n",
    "\t\tcv2.rectangle(self.img,(self.apple_position[0],self.apple_position[1]),(self.apple_position[0]+10,self.apple_position[1]+10),(0,0,255),3)\n",
    "\t\t# Display Snake\n",
    "\t\tfor position in self.snake_position:\n",
    "\t\t\tcv2.rectangle(self.img,(position[0],position[1]),(position[0]+10,position[1]+10),(0,255,0),3)\n",
    "\n",
    "\t\tbutton_direction = action\n",
    "\t\t# Change the head position based on the button direction\n",
    "\t\tif button_direction == 1:\n",
    "\t\t\tself.snake_head[0] += 10\n",
    "\t\telif button_direction == 0:\n",
    "\t\t\tself.snake_head[0] -= 10\n",
    "\t\telif button_direction == 2:\n",
    "\t\t\tself.snake_head[1] += 10\n",
    "\t\telif button_direction == 3:\n",
    "\t\t\tself.snake_head[1] -= 10\n",
    "\n",
    "\t\t# Increase Snake length on eating apple\n",
    "\t\tif self.snake_head == self.apple_position:\n",
    "\t\t\tself.apple_position, self.score = collision_with_apple(self.apple_position, self.score)\n",
    "\t\t\tself.snake_position.insert(0,list(self.snake_head))\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tself.snake_position.insert(0,list(self.snake_head))\n",
    "\t\t\tself.snake_position.pop()\n",
    "\t\t\n",
    "\t\t# On collision kill the snake and print the score\n",
    "\t\tif collision_with_boundaries(self.snake_head) == 1 or collision_with_self(self.snake_position) == 1:\n",
    "\t\t\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\t\t\tself.img = np.zeros((500,500,3),dtype='uint8')\n",
    "\t\t\tcv2.putText(self.img,'Your Score is {}'.format(self.score),(140,250), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "\t\t\tcv2.imshow('a',self.img)\n",
    "\t\t\tself.terminated = True\n",
    "\n",
    "\t\teuclidean_dist_to_apple = np.linalg.norm(np.array(self.snake_head) - np.array(self.apple_position))\n",
    "\t\tself.total_reward = (((len(self.snake_position) - 3)*700) + max(0, 700-euclidean_dist_to_apple))/70 # default length is 3\n",
    "\t\tself.reward = self.total_reward - self.prev_reward\n",
    "\t\tself.prev_reward = self.total_reward\n",
    "\n",
    "\t\tif self.terminated:\n",
    "\t\t\tself.reward = -25\n",
    "\n",
    "\t\tinfo = {}\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "\t\thead_x = self.snake_head[0]\n",
    "\t\thead_y = self.snake_head[1]\n",
    "\n",
    "\t\tsnake_length = len(self.snake_position)\n",
    "\t\tapple_delta_x = self.apple_position[0] - head_x\n",
    "\t\tapple_delta_y = self.apple_position[1] - head_y\n",
    "\n",
    "\t\t# create observation:\n",
    "\n",
    "\t\tobservation = [head_x, head_y, apple_delta_x, apple_delta_y, snake_length] + list(self.prev_actions)\n",
    "\t\tobservation = np.array(observation, dtype=np.float32)\n",
    "\n",
    "\t\tself.truncated = False;\n",
    "\n",
    "\t\treturn observation, self.reward, self.terminated, self.truncated, info\n",
    "\n",
    "\tdef reset(self, seed = None):\n",
    "\t\tsuper().reset(seed=seed)\n",
    "\t\tif seed is not None:\n",
    "\t\t\trandom.seed(seed)\n",
    "\t\telse:\n",
    "\t\t\trandom.seed()\n",
    "        \n",
    "\t\tself.img = np.zeros((500,500,3),dtype='uint8')\n",
    "\t\t# Initial Snake and Apple position\n",
    "\t\tself.snake_position = [[250,250],[240,250],[230,250]]\n",
    "\t\trandom.seed(seed)\n",
    "\t\tself.apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "\t\tself.score = 0\n",
    "\t\tself.prev_button_direction = 1\n",
    "\t\tself.button_direction = 1\n",
    "\t\tself.snake_head = [250,250]\n",
    "\n",
    "\t\tself.prev_reward = 0\n",
    "\n",
    "\t\tself.terminated = False\n",
    "\n",
    "\t\thead_x = self.snake_head[0]\n",
    "\t\thead_y = self.snake_head[1]\n",
    "\n",
    "\t\tsnake_length = len(self.snake_position)\n",
    "\t\tapple_delta_x = self.apple_position[0] - head_x\n",
    "\t\tapple_delta_y = self.apple_position[1] - head_y\n",
    "\n",
    "\t\tself.prev_actions = deque(maxlen = SNAKE_LEN_GOAL)  # however long we aspire the snake to be\n",
    "\t\tfor i in range(SNAKE_LEN_GOAL):\n",
    "\t\t\tself.prev_actions.append(-1) # to create history\n",
    "\n",
    "\t\t# create observation:\n",
    "\t\tobservation = [head_x, head_y, apple_delta_x, apple_delta_y, snake_length] + list(self.prev_actions)\n",
    "\t\tobservation = np.array(observation, dtype=np.float32)\n",
    "\n",
    "\t\tinfo = {}\n",
    "    \n",
    "\t\treturn observation, info\n",
    "\n",
    "\tdef render(self):\n",
    "\t\tt_end = time.time() + 0.05\n",
    "\t\tk = -1\n",
    "\t\tcv2.imshow('snake', self.img)\n",
    "\t\twhile time.time() < t_end:\n",
    "\t\t\tif k == -1:\n",
    "\t\t\t\tk = cv2.waitKey(1)\n",
    "\t\t\telse:\n",
    "\t\t\t\tcontinue"
   ]
  },
  {
   "cell_type": "raw",
   "id": "156b2582-171a-4201-9fb5-c16da00d87ed",
   "metadata": {},
   "source": [
    "env = SnekEnv()\n",
    "episodes = 50\n",
    "\n",
    "for episode in range(episodes):\n",
    "\tdone = False\n",
    "\tobs = env.reset(seed = episode)\n",
    "\tstep = 0\n",
    "\twhile True:#not done:\n",
    "\t\tif step%100 == 0 env.render()\n",
    "\t\trandom_action = env.action_space.sample()\n",
    "\t\tprint(\"action\",random_action)\n",
    "\t\tobs, reward, terminated, truncated, info = env.step(random_action)\n",
    "\t\tdone = terminated or truncated\n",
    "\t\tprint('reward',reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5b84c-0189-4300-a795-0028fd55b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "import time\n",
    "\n",
    "models_dir = f\"models/{int(time.time())}/\"\n",
    "logdir = f\"logs/{int(time.time())}/\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "\tos.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "\tos.makedirs(logdir)\n",
    "\n",
    "env = SnekEnv()\n",
    "env.reset()\n",
    "\n",
    "model = PPO('MlpPolicy', env, device='cpu', verbose=1, tensorboard_log=logdir)\n",
    "\n",
    "TIMESTEPS = 10000\n",
    "iters = 0\n",
    "while True:\n",
    "\titers += 1\n",
    "\t#if iters%10000 == 0: env.render()\n",
    "\tmodel.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"PPO\")\n",
    "\tmodel.save(f\"{models_dir}/{TIMESTEPS*iters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bee21-c44b-4de5-bfad-32fae8410f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716c9e5-4442-44b2-9346-d8f61fb3cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "models_dir = \"/home/prh/Desktop/Local_Prgm_Projects/TetoML/models/1760156174/\"\n",
    "\n",
    "env = SnekEnv()\n",
    "env.reset()\n",
    "\n",
    "model_path = f\"{models_dir}/2030000.zip\"\n",
    "model = PPO.load(model_path, env=env)\n",
    "\n",
    "episodes = 5\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, terminated, truncated, info = env.step(action)\n",
    "        env.render()\n",
    "        done = truncated or terminated\n",
    "        print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74732482-7328-4a34-b3a9-892fd4cec8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
