{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512efe7c-d188-4344-9e3c-40f887dc1adc",
   "metadata": {},
   "source": [
    "# Environment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068efb1-a7ac-4e35-9d7b-b25b3b8fdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "SNAKE_LEN_GOAL = 30\n",
    "\n",
    "def collision_with_apple(apple_position, score):\n",
    "    apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "    score += 1\n",
    "    return apple_position, score\n",
    "\n",
    "def collision_with_boundaries(snake_head):\n",
    "    if snake_head[0]>=500 or snake_head[0]<0 or snake_head[1]>=500 or snake_head[1]<0 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def collision_with_self(snake_position):\n",
    "    snake_head = snake_position[0]\n",
    "    if snake_head in snake_position[1:]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "class SnekEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SnekEnv, self).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # Example for using image as input (channel-first; channel-last also works):\n",
    "        self.observation_space = spaces.Box(low=-500, high=500,\n",
    "                                            shape=(5+SNAKE_LEN_GOAL+SNAKE_LEN_GOAL*2,), dtype=np.float32)\n",
    "        self.rendering = False;\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.prev_actions.append(action)\n",
    "        if self.rendering: cv2.imshow('a',self.img)\n",
    "        #cv2.waitKey(1)\n",
    "        \n",
    "        self.img = np.zeros((500,500,3),dtype='uint8')\n",
    "        # Display Apple\n",
    "        cv2.rectangle(self.img,(self.apple_position[0],self.apple_position[1]),(self.apple_position[0]+10,self.apple_position[1]+10),(0,0,255),3)\n",
    "        # Display Snake\n",
    "        if self.rendering: \n",
    "            for position in self.snake_position:\n",
    "                cv2.rectangle(self.img,(position[0],position[1]),(position[0]+10,position[1]+10),(0,255,0),3)\n",
    "\n",
    "        \n",
    "        button_direction = action\n",
    "\n",
    "        # Prevent 180Â° reversal (don't allow opposite of last direction)\n",
    "        if (action == 0 and self.prev_button_direction == 1) or \\\n",
    "           (action == 1 and self.prev_button_direction == 0) or \\\n",
    "           (action == 2 and self.prev_button_direction == 3) or \\\n",
    "           (action == 3 and self.prev_button_direction == 2):\n",
    "            action = self.prev_button_direction\n",
    "        self.prev_button_direction = action\n",
    "        \n",
    "        # Change the head position based on the button direction\n",
    "        if button_direction == 1:\n",
    "            self.snake_head[0] += 10\n",
    "        elif button_direction == 0:\n",
    "            self.snake_head[0] -= 10\n",
    "        elif button_direction == 2:\n",
    "            self.snake_head[1] += 10\n",
    "        elif button_direction == 3:\n",
    "            self.snake_head[1] -= 10\n",
    "\n",
    "\n",
    "\n",
    "        dist_prev = self.prev_distance_to_apple\n",
    "        dist_curr = np.linalg.norm(np.array(self.snake_head) - np.array(self.apple_position))\n",
    "        reward = 0.01\n",
    "\n",
    "        # On eating apple: increase snake length and reward, otherwise reward if it got closer\n",
    "        if self.snake_head == self.apple_position:\n",
    "            self.apple_position, self.score = collision_with_apple(self.apple_position, self.score)\n",
    "            self.snake_position.insert(0, list(self.snake_head))\n",
    "            reward += 3.0\n",
    "        else:\n",
    "            self.snake_position.insert(0, list(self.snake_head))\n",
    "            self.snake_position.pop()\n",
    "            if dist_curr < dist_prev:\n",
    "                reward += 0.1\n",
    "            else:\n",
    "                reward -= 0.1\n",
    "\n",
    "        # On collision kill snake and punish, render game over screen if rendering\n",
    "        if collision_with_boundaries(self.snake_head) or collision_with_self(self.snake_position):\n",
    "            if self.rendering:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                self.img = np.zeros((500,500,3),dtype='uint8')\n",
    "                cv2.putText(self.img,'Your Score is {}'.format(self.score),(140,250), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "                cv2.imshow('a',self.img)\n",
    "            self.terminated = True\n",
    "            reward -= 5    # Death penalty\n",
    "\n",
    "        # Punish for being too close to tail\n",
    "        for seg in self.snake_position[1:]:\n",
    "            if np.linalg.norm(np.array(self.snake_head) - np.array(seg)) < SNAKE_LEN_GOAL:\n",
    "                reward -= 0.05\n",
    "            \n",
    "        self.prev_distance_to_apple = dist_curr    # \n",
    "        reward -= 0.005   # slight time penalty\n",
    "        self.reward = reward / 5.0\n",
    "    \n",
    "        info = {}\n",
    "    \n",
    "        info = {\"score\": self.score}\n",
    "        \n",
    "    \n",
    "        head_x = self.snake_head[0]\n",
    "        head_y = self.snake_head[1]\n",
    "    \n",
    "        snake_length = len(self.snake_position)\n",
    "        apple_delta_x = self.apple_position[0] - head_x\n",
    "        apple_delta_y = self.apple_position[1] - head_y\n",
    "\n",
    "\n",
    "        \n",
    "        # create observation:\n",
    "        max_tail_len = SNAKE_LEN_GOAL\n",
    "        tail_obs = []\n",
    "        for i in range(1, max_tail_len + 1):\n",
    "            if i < len(self.snake_position):\n",
    "                seg = self.snake_position[i]\n",
    "                tail_obs.append(seg[0] - self.snake_head[0])\n",
    "                tail_obs.append(seg[1] - self.snake_head[1])\n",
    "            else:\n",
    "                tail_obs.extend([0, 0])  # padding\n",
    "        \n",
    "    \n",
    "        observation = [head_x, head_y, apple_delta_x, apple_delta_y, snake_length] + list(self.prev_actions) + tail_obs\n",
    "        observation = np.array(observation, dtype=np.float32)\n",
    "    \n",
    "        self.truncated = False;\n",
    "    \n",
    "        return observation, self.reward, self.terminated, self.truncated, info\n",
    "    \n",
    "    def reset(self, seed = None, render = False):\n",
    "        if render: self.rendering = True\n",
    "        \n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        else:\n",
    "            random.seed()\n",
    "        \n",
    "        self.img = np.zeros((500,500,3),dtype='uint8')\n",
    "        # Initial Snake and Apple position\n",
    "        self.snake_position = [[250,250],[240,250],[230,250]]\n",
    "        \n",
    "        self.apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "        self.score = 0\n",
    "        self.prev_button_direction = 1\n",
    "        self.button_direction = 1\n",
    "        self.snake_head = [250,250]\n",
    "\n",
    "        self.prev_distance_to_apple = np.linalg.norm(np.array(self.snake_head) - np.array(self.apple_position))\n",
    "    \n",
    "        self.prev_reward = 0\n",
    "    \n",
    "        self.terminated = False\n",
    "    \n",
    "        head_x = self.snake_head[0]\n",
    "        head_y = self.snake_head[1]\n",
    "    \n",
    "        snake_length = len(self.snake_position)\n",
    "        apple_delta_x = self.apple_position[0] - head_x\n",
    "        apple_delta_y = self.apple_position[1] - head_y\n",
    "    \n",
    "        self.prev_actions = deque(maxlen = SNAKE_LEN_GOAL)  # however long we aspire the snake to be\n",
    "        for i in range(SNAKE_LEN_GOAL):\n",
    "            self.prev_actions.append(-1) # to create history\n",
    "    \n",
    "        # create observation:\n",
    "        max_tail_len = SNAKE_LEN_GOAL\n",
    "        tail_obs = []\n",
    "        for i in range(1, max_tail_len + 1):\n",
    "            if i < len(self.snake_position):\n",
    "                seg = self.snake_position[i]\n",
    "                tail_obs.append(seg[0] - self.snake_head[0])\n",
    "                tail_obs.append(seg[1] - self.snake_head[1])\n",
    "            else:\n",
    "                tail_obs.extend([0, 0])  # padding\n",
    "        \n",
    "    \n",
    "        observation = [head_x, head_y, apple_delta_x, apple_delta_y, snake_length] + list(self.prev_actions) + tail_obs\n",
    "        observation = np.array(observation, dtype=np.float32)\n",
    "    \n",
    "        info = {}\n",
    "    \n",
    "        return observation, info\n",
    "    \n",
    "    def render(self):\n",
    "        t_end = time.time() + 0.05\n",
    "        k = -1\n",
    "        cv2.imshow('snake', self.img)\n",
    "        while time.time() < t_end:\n",
    "            if k == -1:\n",
    "                k = cv2.waitKey(1)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa7e5c-0ca6-465e-9133-b177d080889f",
   "metadata": {},
   "source": [
    "## Environment Test: Random Actions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "156b2582-171a-4201-9fb5-c16da00d87ed",
   "metadata": {},
   "source": [
    "env = SnekEnv()\n",
    "episodes = 50\n",
    "\n",
    "for episode in range(episodes):\n",
    "\tdone = False\n",
    "\tobs = env.reset(seed = episode)\n",
    "\tstep = 0\n",
    "\twhile True:#not done:\n",
    "\t\tif step%100 == 0 env.render()\n",
    "\t\trandom_action = env.action_space.sample()\n",
    "\t\tprint(\"action\",random_action)\n",
    "\t\tobs, reward, terminated, truncated, info = env.step(random_action)\n",
    "\t\tdone = terminated or truncated\n",
    "\t\tprint('reward',reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24570b0-42da-483b-9ddd-006ae872fe89",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c419e0ca-d1ed-42a0-adb4-a100f080e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "import os\n",
    "import time\n",
    "\n",
    "models_dir = f\"models/{int(time.time())}/\"\n",
    "logdir = f\"logs/{int(time.time())}/\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "\tos.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "\tos.makedirs(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa111a5d-6766-4470-b267-90dd4e7ed1c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "#env = SnekEnv()\n",
    "env = make_vec_env(SnekEnv, n_envs=16, seed=0, vec_env_cls=DummyVecEnv)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7b598-b98f-4b25-b9f2-f3ebf1817844",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(\n",
    "    net_arch=[dict(pi=[256, 256, 128], vf=[256, 256, 128])]\n",
    ")\n",
    "\n",
    "#model = PPO('MlpPolicy', env, device='cpu', verbose=1, tensorboard_log=logdir)\n",
    "#model = PPO('MlpPolicy', env, device='cuda', verbose=1, n_steps=512, n_epochs=5, tensorboard_log=logdir)\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    n_steps=1024,\n",
    "    batch_size=4096,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    ent_coef=0.01,\n",
    "    learning_rate=3e-4,\n",
    "    clip_range=0.2,\n",
    "    device=\"cuda\",\n",
    "    verbose=1,\n",
    "    tensorboard_log=logdir,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856817a2-1ac4-4b43-8dd2-d426110c3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75bb3e-266d-40a8-8462-600d5898be45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for k, v in model.__dict__.items():\n",
    "#    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d476356-9a2b-4473-9def-d8667122f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class ScoreLoggerCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        for info in infos:\n",
    "            if \"score\" in info:\n",
    "                self.logger.record(\"env/score\", info[\"score\"])\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c71ee-3535-4ddf-88ef-84b9d37b12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS = 100000\n",
    "iters = 0\n",
    "logcb = ScoreLoggerCallback()\n",
    "\n",
    "\n",
    "\n",
    "while True:    # Train indefinitely\n",
    "    iters += 1\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"PPO\", callback=logcb, progress_bar=True)\n",
    "    model.save(f\"{models_dir}/{TIMESTEPS*iters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb79c2-4226-46d6-8144-a7e3be43325e",
   "metadata": {},
   "source": [
    "# Load and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255973b5-8d27-458a-b5f7-0efb2038801a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "models_dir = \"/home/prh/Desktop/Local_Prgm_Projects/TetoML/Exploration/Round 2/models/1760239689/\"\n",
    "\n",
    "env = SnekEnv()\n",
    "env.reset(render = True)\n",
    "\n",
    "model_path = f\"{models_dir}/1300000.zip\"\n",
    "model = PPO.load(model_path, env=env)\n",
    "\n",
    "episodes = 1\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, terminated, truncated, info = env.step(action)\n",
    "        env.render()\n",
    "        done = truncated or terminated\n",
    "        print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74732482-7328-4a34-b3a9-892fd4cec8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
